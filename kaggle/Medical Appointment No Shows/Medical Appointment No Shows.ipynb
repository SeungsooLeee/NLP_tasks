{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Appointment No Shows\n",
    "\n",
    "## Why do 30% of patients miss their scheduled appointments?\n",
    "\n",
    "### Context\n",
    "\n",
    "A person makes a doctor appointment, receives all the instructions and no-show. Who to blame? If that is helpful somehow to you knowledge and work - please up vote.\n",
    "\n",
    "### Content\n",
    "\n",
    "300k medical appointments of the public healthcare of the capital city of Vitoria-ES and its 15 variables (characteristics) of each. The most important one if the patient show-up or no-show the appointment. Variable names are self-explanatory, if you have doubts, just let me know! Handcap is the total amount of handcaps a person presents, it is not binary.\n",
    "\n",
    "Version 2 - has appointments groups by patients IDs. scholarship variable means this concept = https://en.wikipedia.org/wiki/Bolsa_Fam%C3%ADlia\n",
    "\n",
    "### Inspiration\n",
    "\n",
    "What if that possible to predict someone to no-show an appointment?\n",
    "\n",
    "### Acknowledgments\n",
    "\n",
    "Municipality of Vitoria and its forward thinking and leading position in terms of data maturity that is helping the world to better understand human behavior.\n",
    "Aquarela Advanced Analytics - For the dozens of hours of analysis given for free on this project.\n",
    "All Kaggle users that are spreading the ideas, codes and knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load the necessary packages and get an overview of what we are dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = pd.read_csv('noshow.csv')\n",
    "data['Gender'] = data['Gender'].replace('M',0).replace('F',1)\n",
    "data['No-show'] = data['No-show'].replace('Yes',0 ).replace('No',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get rid of typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PatientId', 'AppointmentID', 'Gender', 'AppointmentData',\n",
      "       'AppointmentDay', 'Age', 'Neighbourhood', 'Scholarship', 'Hipertension',\n",
      "       'Diabetes', 'Alcoholism', 'Handicap', 'SMS_received', 'noshow'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientId</th>\n",
       "      <th>AppointmentID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AppointmentData</th>\n",
       "      <th>AppointmentDay</th>\n",
       "      <th>Age</th>\n",
       "      <th>Neighbourhood</th>\n",
       "      <th>Scholarship</th>\n",
       "      <th>Hipertension</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Alcoholism</th>\n",
       "      <th>Handicap</th>\n",
       "      <th>SMS_received</th>\n",
       "      <th>noshow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.987250e+13</td>\n",
       "      <td>5642903</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-29T18:38:08Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>62</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.589978e+14</td>\n",
       "      <td>5642503</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-29T16:08:27Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>56</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.262962e+12</td>\n",
       "      <td>5642549</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-29T16:19:04Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>62</td>\n",
       "      <td>MATA DA PRAIA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.679512e+11</td>\n",
       "      <td>5642828</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-29T17:29:31Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>8</td>\n",
       "      <td>PONTAL DE CAMBURI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.841186e+12</td>\n",
       "      <td>5642494</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-29T16:07:23Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>56</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PatientId  AppointmentID  Gender       AppointmentData  \\\n",
       "0  2.987250e+13        5642903       1  2016-04-29T18:38:08Z   \n",
       "1  5.589978e+14        5642503       0  2016-04-29T16:08:27Z   \n",
       "2  4.262962e+12        5642549       1  2016-04-29T16:19:04Z   \n",
       "3  8.679512e+11        5642828       1  2016-04-29T17:29:31Z   \n",
       "4  8.841186e+12        5642494       1  2016-04-29T16:07:23Z   \n",
       "\n",
       "         AppointmentDay  Age      Neighbourhood  Scholarship  Hipertension  \\\n",
       "0  2016-04-29T00:00:00Z   62    JARDIM DA PENHA            0             1   \n",
       "1  2016-04-29T00:00:00Z   56    JARDIM DA PENHA            0             0   \n",
       "2  2016-04-29T00:00:00Z   62      MATA DA PRAIA            0             0   \n",
       "3  2016-04-29T00:00:00Z    8  PONTAL DE CAMBURI            0             0   \n",
       "4  2016-04-29T00:00:00Z   56    JARDIM DA PENHA            0             1   \n",
       "\n",
       "   Diabetes  Alcoholism  Handicap  SMS_received  noshow  \n",
       "0         0           0         0             0       1  \n",
       "1         0           0         0             0       1  \n",
       "2         0           0         0             0       1  \n",
       "3         0           0         0             0       1  \n",
       "4         1           0         0             0       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.rename(columns = {'ScheduledDay':'AppointmentData',\n",
    "                         'Alcoolism': 'Alchoholism',\n",
    "                         'HiperTension': 'Hypertension',\n",
    "                         'Handcap': 'Handicap', 'No-show' : 'noshow'}, inplace = True)\n",
    "\n",
    "print(data.columns)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2016-04-29 18:38:08\n",
      "1   2016-04-29 16:08:27\n",
      "2   2016-04-29 16:19:04\n",
      "3   2016-04-29 17:29:31\n",
      "4   2016-04-29 16:07:23\n",
      "Name: AppointmentData, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "data.AppointmentData = data.AppointmentData.apply(np.datetime64)\n",
    "print (data.AppointmentData[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### checking for errors and NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: [-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 115]\n",
      "Gender: [1 0]\n",
      "Scholarship: [0 1]\n",
      "Hipertension: [1 0]\n",
      "Diabetes: [0 1]\n",
      "Alcoholism: [0 1]\n",
      "Handicap: [0 1 2 3 4]\n",
      "SMS_received: [0 1]\n",
      "No-show: [1 0]\n"
     ]
    }
   ],
   "source": [
    "print('Age:',sorted(data.Age.unique()))\n",
    "print('Gender:', data.Gender.unique())\n",
    "print('Scholarship:', data.Scholarship.unique())\n",
    "print('Hipertension:', data.Hipertension.unique())\n",
    "print('Diabetes:', data.Diabetes.unique())\n",
    "print('Alcoholism:', data.Alcoholism.unique())\n",
    "print('Handicap:', data.Handicap.unique())\n",
    "print('SMS_received:', data.SMS_received.unique())\n",
    "print('No-show:', data.noshow.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cleaning Age data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data.Age >= 0) & (data.Age <= 95)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTING WHETHER A PERSON WILL BE SHOWING UP\n",
    "\n",
    "### Feature\n",
    "1. Gender \n",
    "2. Age \n",
    "3. Scholarship \n",
    "4. Hipertension \n",
    "5. Diabetes \n",
    "6. Alcoholism \n",
    "7. Handicap \n",
    "8. SMS_received"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train, Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = np.array(data[['Gender', 'Age','Scholarship', 'Hipertension', 'Diabetes',\n",
    "                         'Alcoholism', 'Handicap','SMS_received']])\n",
    "target = np.array(data.noshow)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature, target, test_size=0.33, random_state=42)\n",
    "\n",
    "y_train_0 = y_train\n",
    "y_test_0 = y_test\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74021, 8)\n",
      "(36459, 8)\n",
      "(74021, 1)\n",
      "(36459, 1)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_train.shape)\n",
    "print (y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Neual network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 3.4358701705932617\n",
      "Loss : 0.4907403886318207\n",
      "Loss : 0.49031275510787964\n",
      "Loss : 0.4902864396572113\n",
      "Loss : 0.4898890554904938\n",
      "Loss : 0.48964858055114746\n",
      "[1.0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "SEED = 200\n",
    "\n",
    "# make model, 3 layer\n",
    "x = tf.placeholder(dtype = tf.float32, shape=[None, 8])\n",
    "y = tf.placeholder(dtype = tf.float32, shape=[None, 1])\n",
    "\n",
    "W1 = tf.get_variable(\"W1\", shape =[8,50])\n",
    "b1 = tf.get_variable(\"b1\", shape = [50])\n",
    "h1 = tf.matmul(x, W1) + b1 \n",
    "h1 = tf.nn.relu(h1)\n",
    "\n",
    "W2 = tf.get_variable(\"W2\", shape =[50,100]) \n",
    "b2 = tf.get_variable(\"b2\", shape = [100])\n",
    "h2 = tf.matmul(h1, W2) + b2 \n",
    "h2 = tf.nn.relu(h2)\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape =[100,1]) \n",
    "b3 = tf.get_variable(\"b3\", shape = [1])\n",
    "\n",
    "logits = tf.matmul(h2, W3) + b3\n",
    "#########################################################################\n",
    "\n",
    "#Loss\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "train_op = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "\n",
    "#acc\n",
    "correct_prediction = tf.equal(tf.argmax(logits,1), tf.argmax(y,1))\n",
    "acc = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "############### summary ###############\n",
    "tf.summary.scalar('loss', loss)\n",
    "\n",
    "tf.summary.histogram(\"W1\", W1)\n",
    "tf.summary.histogram(\"b1\", b1)\n",
    "tf.summary.histogram(\"W2\", W2)\n",
    "tf.summary.histogram(\"b2\", b2)\n",
    "tf.summary.histogram(\"W3\", W3)\n",
    "tf.summary.histogram(\"b3\", b3)\n",
    "\n",
    "merge_op = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#graph\n",
    "summary_writer_train_3 = tf.summary.FileWriter(\"./logs/train_my-3\", sess.graph)\n",
    "summary_writer_val_3 = tf.summary.FileWriter(\"./logs/val_my-3\", sess.graph)\n",
    "for step in range(3000):\n",
    "    feed = {x : X_train, y : y_train}\n",
    "    _, loss_train = sess.run([train_op, loss], feed_dict=feed)\n",
    "    \n",
    "    if (step%500) ==0:\n",
    "        print ('Loss : {}'.format(loss_train))\n",
    "        \n",
    "        summary_train = sess.run(merge_op, feed_dict=feed)\n",
    "        summary_writer_train_3.add_summary(summary_train, step)\n",
    "        \n",
    "#         feed_val = {x : x_validation, y : y_validation}\n",
    "#         loss_val = sess.run([loss], feed_dict=feed_val)\n",
    "#         print (\"Loss : {}\".format(loss_val))\n",
    "        \n",
    "#         summary_val = sess.run(merge_op, feed_dict=feed_val)\n",
    "#         summary_writer_val_3.add_summary(summary_val, step)\n",
    "        \n",
    "acc = sess.run([acc], feed_dict={x : X_test, y : y_test})\n",
    "print (acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.0 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf =  MultinomialNB().fit(X_train, y_train_0)\n",
    "print('Accuracy:', round(accuracy_score(y_test_0, clf.predict(X_test)), 2) * 100, '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
